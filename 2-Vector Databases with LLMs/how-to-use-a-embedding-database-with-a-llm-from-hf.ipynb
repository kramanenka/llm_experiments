{
  "cells": [
    {
      "source": [
        "<a href=\"https://www.kaggle.com/code/peremartramanonellas/use-a-vectorial-db-to-optimize-prompts-for-llms?scriptVersionId=187994930\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
      ],
      "metadata": {
        "id": "3_IKSr-4oFIJ"
      },
      "cell_type": "markdown",
      "id": "3_IKSr-4oFIJ"
    },
    {
      "cell_type": "markdown",
      "id": "b884d941",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-25T22:11:51.957387Z",
          "iopub.status.busy": "2023-10-25T22:11:51.956945Z",
          "iopub.status.idle": "2023-10-25T22:11:51.965701Z",
          "shell.execute_reply": "2023-10-25T22:11:51.964581Z",
          "shell.execute_reply.started": "2023-10-25T22:11:51.957351Z"
        },
        "papermill": {
          "duration": 0.01367,
          "end_time": "2024-07-12T16:06:46.15565",
          "exception": false,
          "start_time": "2024-07-12T16:06:46.14198",
          "status": "completed"
        },
        "tags": [],
        "id": "b884d941"
      },
      "source": [
        "\n",
        "<div align=\"center\">\n",
        "<h1><a href=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course\">Learn by Doing LLM Projects</a></h1>\n",
        "    <h3>Understand And Apply Large Language Models</h3>\n",
        "    <h2>HOW TO USE A VECTOR / EMBEDDING DATABASE TO PROVIDE CONTEXT TO A LARGE LANGUAGE MODEL</h2>\n",
        "    by <b>Pere Martra</b>\n",
        "</div>\n",
        "\n",
        "<br>\n",
        "\n",
        "<div align=\"center\">\n",
        "    &nbsp;\n",
        "    <a target=\"_blank\" href=\"https://www.linkedin.com/in/pere-martra/\"><img src=\"https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&logo=linkedin&style=social\"></a>\n",
        "    \n",
        "</div>\n",
        "\n",
        "<br>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6442a230",
      "metadata": {
        "papermill": {
          "duration": 0.012225,
          "end_time": "2024-07-12T16:06:46.180484",
          "exception": false,
          "start_time": "2024-07-12T16:06:46.168259",
          "status": "completed"
        },
        "tags": [],
        "id": "6442a230"
      },
      "source": [
        "### This notebook is part of a comprehensive course on Large Language Models available on GitHub: https://github.com/peremartra/Large-Language-Model-Notebooks-Course. If you want to stay informed about new lessons or updates, simply follow or star the repository.\n",
        "\n",
        "In this notebook we will see how to use an embedding database to store the information that we want to pass to a large language model so that it takes it into account in its responses.\n",
        "\n",
        "The information could be our own documents, or whatever was contained in a business knowledge database.\n",
        "\n",
        "I have prepared the notebook so that it can work with three different Kaggle datasets, so that it is easy to carry out different tests with different Datasets.\n",
        "\n",
        "![VectorDatabase.png](attachment:a73106c8-f286-41fc-b9d7-66638412114c.png)\n",
        "### Feel Free to fork or edit the noteboook for you own convenience. Please consider ***UPVOTING IT***. It helps others to discover the notebook, and it encourages me to continue publishing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27a636ba",
      "metadata": {
        "papermill": {
          "duration": 0.012023,
          "end_time": "2024-07-12T16:06:46.205018",
          "exception": false,
          "start_time": "2024-07-12T16:06:46.192995",
          "status": "completed"
        },
        "tags": [],
        "id": "27a636ba"
      },
      "source": [
        "# Import and load the libraries.\n",
        "To start we need to install the necesary Python packages.\n",
        "* **[sentence transformers](http:/www.sbert.net/)**. This library is necessary to transform the sentences into fixed-length vectors, also know as embeddings.\n",
        "* **[xformers](https://github.com/facebookresearch/xformers)**. it's a package that provides libraries an utilities to facilitate the work with transformers models. We need to install in order to avoid an error when we work with the model and embeddings.  \n",
        "* **[chromadb](https://www.trychroma.com/)**. This is our vector Database. ChromaDB is easy to use and open source, maybe the most used Vector Database used to store embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e40c73b9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-12T16:06:46.231579Z",
          "iopub.status.busy": "2024-07-12T16:06:46.231145Z",
          "iopub.status.idle": "2024-07-12T16:07:16.752439Z",
          "shell.execute_reply": "2024-07-12T16:07:16.750816Z"
        },
        "papermill": {
          "duration": 30.537837,
          "end_time": "2024-07-12T16:07:16.755336",
          "exception": false,
          "start_time": "2024-07-12T16:06:46.217499",
          "status": "completed"
        },
        "tags": [],
        "id": "e40c73b9"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers==4.41.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9225070c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-12T16:07:16.784028Z",
          "iopub.status.busy": "2024-07-12T16:07:16.783606Z",
          "iopub.status.idle": "2024-07-12T16:08:28.459947Z",
          "shell.execute_reply": "2024-07-12T16:08:28.458693Z"
        },
        "papermill": {
          "duration": 71.693563,
          "end_time": "2024-07-12T16:08:28.462852",
          "exception": false,
          "start_time": "2024-07-12T16:07:16.769289",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "id": "9225070c",
        "outputId": "f97ee8e8-2f69-4eaa-fa6a-dbfedadcd073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
            "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\r\n",
            "google-cloud-pubsublite 1.8.2 requires overrides<7.0.0,>=6.0.1, but you have overrides 7.7.0 which is incompatible.\r\n",
            "jupyterlab-lsp 4.2.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
            "kfp 2.0.1 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
            "kfp 2.0.1 requires kubernetes<27,>=8.0.0, but you have kubernetes 30.1.0 which is incompatible.\r\n",
            "opentelemetry-exporter-otlp 1.18.0 requires opentelemetry-exporter-otlp-proto-grpc==1.18.0, but you have opentelemetry-exporter-otlp-proto-grpc 1.25.0 which is incompatible.\r\n",
            "opentelemetry-exporter-otlp-proto-http 1.18.0 requires opentelemetry-exporter-otlp-proto-common==1.18.0, but you have opentelemetry-exporter-otlp-proto-common 1.25.0 which is incompatible.\r\n",
            "opentelemetry-exporter-otlp-proto-http 1.18.0 requires opentelemetry-proto==1.18.0, but you have opentelemetry-proto 1.25.0 which is incompatible.\r\n",
            "opentelemetry-exporter-otlp-proto-http 1.18.0 requires opentelemetry-sdk~=1.18.0, but you have opentelemetry-sdk 1.25.0 which is incompatible.\r\n",
            "ray 2.5.1 requires grpcio<=1.51.3,>=1.42.0; python_version >= \"3.10\" and sys_platform != \"darwin\", but you have grpcio 1.64.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q sentence-transformers==2.2.2\n",
        "#!pip install -q xformers==0.0.23\n",
        "!pip install -q chromadb==0.4.20"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f80c3c9",
      "metadata": {
        "papermill": {
          "duration": 0.01265,
          "end_time": "2024-07-12T16:08:28.488682",
          "exception": false,
          "start_time": "2024-07-12T16:08:28.476032",
          "status": "completed"
        },
        "tags": [],
        "id": "1f80c3c9"
      },
      "source": [
        "I'm sure that you know the next two packages: Numpy and Pandas, maybe the most used python libraries.\n",
        "\n",
        "Numpy is a powerful library for numerical computing.\n",
        "\n",
        "Pandas is a library for data manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8448ce50",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-12T16:08:28.516764Z",
          "iopub.status.busy": "2024-07-12T16:08:28.516327Z",
          "iopub.status.idle": "2024-07-12T16:08:28.522026Z",
          "shell.execute_reply": "2024-07-12T16:08:28.520939Z"
        },
        "papermill": {
          "duration": 0.02294,
          "end_time": "2024-07-12T16:08:28.524409",
          "exception": false,
          "start_time": "2024-07-12T16:08:28.501469",
          "status": "completed"
        },
        "tags": [],
        "id": "8448ce50"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4edf6bf8",
      "metadata": {
        "papermill": {
          "duration": 0.01268,
          "end_time": "2024-07-12T16:08:28.549816",
          "exception": false,
          "start_time": "2024-07-12T16:08:28.537136",
          "status": "completed"
        },
        "tags": [],
        "id": "4edf6bf8"
      },
      "source": [
        "# Load the Dataset\n",
        "As you can see the notebook is ready to work with three different Datasets. Just uncomment the lines of the Dataset you want to use.\n",
        "\n",
        "I selected Datasets with News. Two of them have just a brief decription of the new, but the other contains the full text.\n",
        "\n",
        "As we are working in a free and limited space, and we can use just 30 gb of memory I limited the number of news to use with the variable MAX_NEWS.\n",
        "\n",
        "The name of the field containing the text of the new is stored in the variable *DOCUMENT* and the metadata in *TOPIC*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04db13e2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-12T16:08:28.577398Z",
          "iopub.status.busy": "2024-07-12T16:08:28.576984Z",
          "iopub.status.idle": "2024-07-12T16:08:29.513016Z",
          "shell.execute_reply": "2024-07-12T16:08:29.511863Z"
        },
        "papermill": {
          "duration": 0.952812,
          "end_time": "2024-07-12T16:08:29.515785",
          "exception": false,
          "start_time": "2024-07-12T16:08:28.562973",
          "status": "completed"
        },
        "tags": [],
        "id": "04db13e2"
      },
      "outputs": [],
      "source": [
        "news = pd.read_csv('/kaggle/input/topic-labeled-news-dataset/labelled_newscatcher_dataset.csv', sep=';')\n",
        "MAX_NEWS = 1000\n",
        "DOCUMENT=\"title\"\n",
        "TOPIC=\"topic\"\n",
        "\n",
        "#news = pd.read_csv('/kaggle/input/bbc-news/bbc_news.csv')\n",
        "#MAX_NEWS = 1000\n",
        "#DOCUMENT=\"description\"\n",
        "#TOPIC=\"title\"\n",
        "\n",
        "#news = pd.read_csv('/kaggle/input/mit-ai-news-published-till-2023/articles.csv')\n",
        "#MAX_NEWS = 100\n",
        "#DOCUMENT=\"Article Body\"\n",
        "#TOPIC=\"Article Header\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "549c36c3",
      "metadata": {
        "papermill": {
          "duration": 0.012361,
          "end_time": "2024-07-12T16:08:29.540904",
          "exception": false,
          "start_time": "2024-07-12T16:08:29.528543",
          "status": "completed"
        },
        "tags": [],
        "id": "549c36c3"
      },
      "source": [
        "ChromaDB requires that the data has a unique identifier. We can make it with this statement, which will create a new column called **Id**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52a7e9f7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-12T16:08:29.568185Z",
          "iopub.status.busy": "2024-07-12T16:08:29.567767Z",
          "iopub.status.idle": "2024-07-12T16:08:29.594511Z",
          "shell.execute_reply": "2024-07-12T16:08:29.593509Z"
        },
        "papermill": {
          "duration": 0.043406,
          "end_time": "2024-07-12T16:08:29.596982",
          "exception": false,
          "start_time": "2024-07-12T16:08:29.553576",
          "status": "completed"
        },
        "tags": [],
        "id": "52a7e9f7",
        "outputId": "c46e37c1-0c67-49a6-a544-1cfbaec9515b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "      <th>link</th>\n",
              "      <th>domain</th>\n",
              "      <th>published_date</th>\n",
              "      <th>title</th>\n",
              "      <th>lang</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SCIENCE</td>\n",
              "      <td>https://www.eurekalert.org/pub_releases/2020-0...</td>\n",
              "      <td>eurekalert.org</td>\n",
              "      <td>2020-08-06 13:59:45</td>\n",
              "      <td>A closer look at water-splitting's solar fuel ...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SCIENCE</td>\n",
              "      <td>https://www.pulse.ng/news/world/an-irresistibl...</td>\n",
              "      <td>pulse.ng</td>\n",
              "      <td>2020-08-12 15:14:19</td>\n",
              "      <td>An irresistible scent makes locusts swarm, stu...</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SCIENCE</td>\n",
              "      <td>https://www.express.co.uk/news/science/1322607...</td>\n",
              "      <td>express.co.uk</td>\n",
              "      <td>2020-08-13 21:01:00</td>\n",
              "      <td>Artificial intelligence warning: AI will know ...</td>\n",
              "      <td>en</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SCIENCE</td>\n",
              "      <td>https://www.ndtv.com/world-news/glaciers-could...</td>\n",
              "      <td>ndtv.com</td>\n",
              "      <td>2020-08-03 22:18:26</td>\n",
              "      <td>Glaciers Could Have Sculpted Mars Valleys: Study</td>\n",
              "      <td>en</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SCIENCE</td>\n",
              "      <td>https://www.thesun.ie/tech/5742187/perseid-met...</td>\n",
              "      <td>thesun.ie</td>\n",
              "      <td>2020-08-12 19:54:36</td>\n",
              "      <td>Perseid meteor shower 2020: What time and how ...</td>\n",
              "      <td>en</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     topic                                               link          domain  \\\n",
              "0  SCIENCE  https://www.eurekalert.org/pub_releases/2020-0...  eurekalert.org   \n",
              "1  SCIENCE  https://www.pulse.ng/news/world/an-irresistibl...        pulse.ng   \n",
              "2  SCIENCE  https://www.express.co.uk/news/science/1322607...   express.co.uk   \n",
              "3  SCIENCE  https://www.ndtv.com/world-news/glaciers-could...        ndtv.com   \n",
              "4  SCIENCE  https://www.thesun.ie/tech/5742187/perseid-met...       thesun.ie   \n",
              "\n",
              "        published_date                                              title  \\\n",
              "0  2020-08-06 13:59:45  A closer look at water-splitting's solar fuel ...   \n",
              "1  2020-08-12 15:14:19  An irresistible scent makes locusts swarm, stu...   \n",
              "2  2020-08-13 21:01:00  Artificial intelligence warning: AI will know ...   \n",
              "3  2020-08-03 22:18:26   Glaciers Could Have Sculpted Mars Valleys: Study   \n",
              "4  2020-08-12 19:54:36  Perseid meteor shower 2020: What time and how ...   \n",
              "\n",
              "  lang  id  \n",
              "0   en   0  \n",
              "1   en   1  \n",
              "2   en   2  \n",
              "3   en   3  \n",
              "4   en   4  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "news[\"id\"] = news.index\n",
        "news.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d2d90f0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-12T16:08:29.6249Z",
          "iopub.status.busy": "2024-07-12T16:08:29.624494Z",
          "iopub.status.idle": "2024-07-12T16:08:29.629882Z",
          "shell.execute_reply": "2024-07-12T16:08:29.62879Z"
        },
        "papermill": {
          "duration": 0.022406,
          "end_time": "2024-07-12T16:08:29.632353",
          "exception": false,
          "start_time": "2024-07-12T16:08:29.609947",
          "status": "completed"
        },
        "tags": [],
        "id": "9d2d90f0"
      },
      "outputs": [],
      "source": [
        "#Because it is just a course we select a small portion of News.\n",
        "subset_news = news.head(MAX_NEWS)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a6fc584",
      "metadata": {
        "papermill": {
          "duration": 0.012949,
          "end_time": "2024-07-12T16:08:29.658421",
          "exception": false,
          "start_time": "2024-07-12T16:08:29.645472",
          "status": "completed"
        },
        "tags": [],
        "id": "5a6fc584"
      },
      "source": [
        "# Import and configure the Vector Database\n",
        "I'm going to use ChromaDB, the most popular OpenSource embedding Database.\n",
        "\n",
        "First we need to import ChromaDB, and after that import the **Settings** class from **chromadb.config** module. This class allows us to change the setting for the ChromaDB system, and customize its behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82035556",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-12T16:08:29.686168Z",
          "iopub.status.busy": "2024-07-12T16:08:29.685736Z",
          "iopub.status.idle": "2024-07-12T16:08:30.542685Z",
          "shell.execute_reply": "2024-07-12T16:08:30.541615Z"
        },
        "papermill": {
          "duration": 0.874542,
          "end_time": "2024-07-12T16:08:30.546158",
          "exception": false,
          "start_time": "2024-07-12T16:08:29.671616",
          "status": "completed"
        },
        "tags": [],
        "id": "82035556"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "from chromadb.config import Settings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15d260ae",
      "metadata": {
        "papermill": {
          "duration": 0.015035,
          "end_time": "2024-07-12T16:08:30.577917",
          "exception": false,
          "start_time": "2024-07-12T16:08:30.562882",
          "status": "completed"
        },
        "tags": [],
        "id": "15d260ae"
      },
      "source": [
        "Now we need to create the seetings object calling the **Settings** function imported previously. We store the object in the variable **settings_chroma**.\n",
        "\n",
        "Is necessary to inform two parameters\n",
        "* chroma_db_impl. Here we specify the database implementation and the format how store the data. I choose ***duckdb***, because his high-performace. It operate primarly in memory. And is fully compatible with SQL. The store format ***parquet*** is good for tabular data. With good compression rates and performance.\n",
        "\n",
        "* persist_directory: It just contains the directory where the data will be stored. Is possible work without a directory and the data will be stored in memory without persistece, but Kaggle dosn't support that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eee78a0f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-12T16:08:30.613693Z",
          "iopub.status.busy": "2024-07-12T16:08:30.612549Z",
          "iopub.status.idle": "2024-07-12T16:08:31.202842Z",
          "shell.execute_reply": "2024-07-12T16:08:31.201676Z"
        },
        "papermill": {
          "duration": 0.613695,
          "end_time": "2024-07-12T16:08:31.206102",
          "exception": false,
          "start_time": "2024-07-12T16:08:30.592407",
          "status": "completed"
        },
        "tags": [],
        "id": "eee78a0f"
      },
      "outputs": [],
      "source": [
        "#OLD VERSION\n",
        "#settings_chroma = Settings(chroma_db_impl=\"duckdb+parquet\",\n",
        "#                          persist_directory='./input')\n",
        "#chroma_client = chromadb.Client(settings_chroma)\n",
        "\n",
        "#NEW VERSION => 0.40\n",
        "chroma_client = chromadb.PersistentClient(path=\"/path/to/persist/directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1e1d2fa",
      "metadata": {
        "papermill": {
          "duration": 0.01291,
          "end_time": "2024-07-12T16:08:31.23693",
          "exception": false,
          "start_time": "2024-07-12T16:08:31.22402",
          "status": "completed"
        },
        "tags": [],
        "id": "b1e1d2fa"
      },
      "source": [
        "# Filling and Querying the ChromaDB Database\n",
        "The Data in ChromaDB is stored in collections. If the collection exist we need to delete it.\n",
        "\n",
        "In the next lines, we are creating the collection by calling the ***create_collection*** function in the ***chroma_client*** created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d41b73cc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-12T16:08:31.266281Z",
          "iopub.status.busy": "2024-07-12T16:08:31.265328Z",
          "iopub.status.idle": "2024-07-12T16:08:31.270639Z",
          "shell.execute_reply": "2024-07-12T16:08:31.26957Z"
        },
        "papermill": {
          "duration": 0.023518,
          "end_time": "2024-07-12T16:08:31.273489",
          "exception": false,
          "start_time": "2024-07-12T16:08:31.249971",
          "status": "completed"
        },
        "tags": [],
        "id": "d41b73cc"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ae2ef8d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-12T16:08:31.311254Z",
          "iopub.status.busy": "2024-07-12T16:08:31.31082Z",
          "iopub.status.idle": "2024-07-12T16:08:31.372055Z",
          "shell.execute_reply": "2024-07-12T16:08:31.370847Z"
        },
        "papermill": {
          "duration": 0.083165,
          "end_time": "2024-07-12T16:08:31.375242",
          "exception": false,
          "start_time": "2024-07-12T16:08:31.292077",
          "status": "completed"
        },
        "tags": [],
        "id": "9ae2ef8d"
      },
      "outputs": [],
      "source": [
        "collection_name = \"news_collection\"+datetime.now().strftime(\"%s\")\n",
        "if len(chroma_client.list_collections()) > 0 and collection_name in [chroma_client.list_collections()[0].name]:\n",
        "        chroma_client.delete_collection(name=collection_name)\n",
        "\n",
        "collection = chroma_client.create_collection(name=collection_name)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5268136c",
      "metadata": {
        "papermill": {
          "duration": 0.018037,
          "end_time": "2024-07-12T16:08:31.412298",
          "exception": false,
          "start_time": "2024-07-12T16:08:31.394261",
          "status": "completed"
        },
        "tags": [],
        "id": "5268136c"
      },
      "source": [
        "It's time to add the data to the collection. Using the function ***add*** we need to inform, at least ***documents***, ***metadatas*** and ***ids***.\n",
        "* In the **document** we store the big text, it's a different column in each Dataset.\n",
        "* In **metadatas**, we can informa a list of topics.\n",
        "* In **id** we need to inform an unique identificator for each row. It MUST be unique! I'm creating the ID using the range of MAX_NEWS.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ac852b1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-12T16:08:31.452981Z",
          "iopub.status.busy": "2024-07-12T16:08:31.452434Z",
          "iopub.status.idle": "2024-07-12T16:09:48.217981Z",
          "shell.execute_reply": "2024-07-12T16:09:48.216949Z"
        },
        "papermill": {
          "duration": 76.789481,
          "end_time": "2024-07-12T16:09:48.220779",
          "exception": false,
          "start_time": "2024-07-12T16:08:31.431298",
          "status": "completed"
        },
        "tags": [],
        "id": "1ac852b1",
        "outputId": "d771e59d-0423-4305-d5be-2d94463682eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:07<00:00, 10.9MiB/s]\n"
          ]
        }
      ],
      "source": [
        "collection.add(\n",
        "    documents=subset_news[DOCUMENT].tolist(),\n",
        "    metadatas=[{TOPIC: topic} for topic in subset_news[TOPIC].tolist()],\n",
        "    ids=[f\"id{x}\" for x in range(MAX_NEWS)],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d5c788e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-12T16:09:48.257951Z",
          "iopub.status.busy": "2024-07-12T16:09:48.25752Z",
          "iopub.status.idle": "2024-07-12T16:09:48.377993Z",
          "shell.execute_reply": "2024-07-12T16:09:48.376725Z"
        },
        "papermill": {
          "duration": 0.142327,
          "end_time": "2024-07-12T16:09:48.380548",
          "exception": false,
          "start_time": "2024-07-12T16:09:48.238221",
          "status": "completed"
        },
        "tags": [],
        "id": "1d5c788e",
        "outputId": "8d4872b0-8a9c-42ee-d8dc-9627ffc3f9e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ids': [['id173', 'id829', 'id117', 'id535', 'id141', 'id218', 'id390', 'id273', 'id56', 'id900']], 'distances': [[0.8593594431877136, 1.0294400453567505, 1.0793331861495972, 1.093001127243042, 1.1329681873321533, 1.2130440473556519, 1.214331865310669, 1.2164140939712524, 1.2220635414123535, 1.2754170894622803]], 'metadatas': [[{'topic': 'TECHNOLOGY'}, {'topic': 'TECHNOLOGY'}, {'topic': 'TECHNOLOGY'}, {'topic': 'TECHNOLOGY'}, {'topic': 'TECHNOLOGY'}, {'topic': 'TECHNOLOGY'}, {'topic': 'TECHNOLOGY'}, {'topic': 'TECHNOLOGY'}, {'topic': 'TECHNOLOGY'}, {'topic': 'TECHNOLOGY'}]], 'embeddings': None, 'documents': [['The Legendary Toshiba is Officially Done With Making Laptops', '3 gaming laptop deals you can’t afford to miss today', 'Lenovo and HP control half of the global laptop market', 'Asus ROG Zephyrus G14 gaming laptop announced in India', 'Acer Swift 3 featuring a 10th-generation Intel Ice Lake CPU, 2K screen, and more launched in India for INR 64999 (US$865)', \"Apple's Next MacBook Could Be the Cheapest in Company's History\", \"Features of Huawei's Desktop Computer Revealed\", 'Redmi to launch its first gaming laptop on August 14: Here are all the details', 'Toshiba shuts the lid on laptops after 35 years', 'This is the cheapest Windows PC by a mile and it even has a spare SSD slot']], 'uris': None, 'data': None}\n"
          ]
        }
      ],
      "source": [
        "results = collection.query(query_texts=[\"laptop\"], n_results=10 )\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51a57488",
      "metadata": {
        "papermill": {
          "duration": 0.017367,
          "end_time": "2024-07-12T16:09:48.415601",
          "exception": false,
          "start_time": "2024-07-12T16:09:48.398234",
          "status": "completed"
        },
        "tags": [],
        "id": "51a57488"
      },
      "source": [
        "## Vector MAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a6d987a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-12T16:09:48.453093Z",
          "iopub.status.busy": "2024-07-12T16:09:48.452117Z",
          "iopub.status.idle": "2024-07-12T16:09:49.624769Z",
          "shell.execute_reply": "2024-07-12T16:09:49.623594Z"
        },
        "papermill": {
          "duration": 1.194434,
          "end_time": "2024-07-12T16:09:49.627701",
          "exception": false,
          "start_time": "2024-07-12T16:09:48.433267",
          "status": "completed"
        },
        "tags": [],
        "id": "8a6d987a",
        "outputId": "5417fd77-4ec0-42eb-a21b-00bb61a7e9fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd7decf3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-12T16:09:49.665205Z",
          "iopub.status.busy": "2024-07-12T16:09:49.664783Z",
          "iopub.status.idle": "2024-07-12T16:09:49.672432Z",
          "shell.execute_reply": "2024-07-12T16:09:49.671525Z"
        },
        "papermill": {
          "duration": 0.029261,
          "end_time": "2024-07-12T16:09:49.67479",
          "exception": false,
          "start_time": "2024-07-12T16:09:49.645529",
          "status": "completed"
        },
        "tags": [],
        "id": "bd7decf3"
      },
      "outputs": [],
      "source": [
        "getado = collection.get(ids=\"id141\",\n",
        "                       include=[\"documents\", \"embeddings\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9e07e01",
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2024-07-12T16:09:49.711316Z",
          "iopub.status.busy": "2024-07-12T16:09:49.71092Z",
          "iopub.status.idle": "2024-07-12T16:09:49.723984Z",
          "shell.execute_reply": "2024-07-12T16:09:49.722853Z"
        },
        "papermill": {
          "duration": 0.034424,
          "end_time": "2024-07-12T16:09:49.72658",
          "exception": false,
          "start_time": "2024-07-12T16:09:49.692156",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "id": "a9e07e01",
        "outputId": "86d894f2-74ec-4f57-9609-5d9f7d58a18a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[-0.0808560848236084,\n",
              "  -0.049963705241680145,\n",
              "  -0.023777484893798828,\n",
              "  -0.011053602211177349,\n",
              "  0.02665771171450615,\n",
              "  -0.04479333013296127,\n",
              "  -0.02889663353562355,\n",
              "  0.026656104251742363,\n",
              "  0.0014397227205336094,\n",
              "  -0.016407841816544533,\n",
              "  0.0653492733836174,\n",
              "  -0.06901992857456207,\n",
              "  -0.05748078227043152,\n",
              "  0.010111615061759949,\n",
              "  0.05043035000562668,\n",
              "  -0.002057764446362853,\n",
              "  0.07256408035755157,\n",
              "  -0.12437368929386139,\n",
              "  0.010659442283213139,\n",
              "  -0.10942046344280243,\n",
              "  -0.01143240462988615,\n",
              "  -0.010376011952757835,\n",
              "  -0.020610831677913666,\n",
              "  -0.024394094944000244,\n",
              "  0.07828476279973984,\n",
              "  0.005820558872073889,\n",
              "  0.023317726328969002,\n",
              "  -0.08243829756975174,\n",
              "  -0.02726505883038044,\n",
              "  0.0046674772165715694,\n",
              "  0.004340188577771187,\n",
              "  0.03252805024385452,\n",
              "  -0.026030974462628365,\n",
              "  0.07963905483484268,\n",
              "  0.042182061821222305,\n",
              "  -0.12119994312524796,\n",
              "  0.04907083883881569,\n",
              "  -0.07625846564769745,\n",
              "  0.04331624507904053,\n",
              "  -0.08360457420349121,\n",
              "  -0.07140401750802994,\n",
              "  -0.018792513757944107,\n",
              "  0.036049388349056244,\n",
              "  0.042845625430345535,\n",
              "  0.025760438293218613,\n",
              "  0.03972514718770981,\n",
              "  -0.007091294974088669,\n",
              "  0.035189948976039886,\n",
              "  0.027369096875190735,\n",
              "  0.009289839304983616,\n",
              "  -0.03916166350245476,\n",
              "  -0.037401288747787476,\n",
              "  -0.03369569778442383,\n",
              "  -0.06543102860450745,\n",
              "  0.01919756457209587,\n",
              "  -0.009083813056349754,\n",
              "  0.022507958114147186,\n",
              "  -0.04346753656864166,\n",
              "  0.03663364797830582,\n",
              "  0.09003791213035583,\n",
              "  0.037535011768341064,\n",
              "  -0.04698672145605087,\n",
              "  -0.021450482308864594,\n",
              "  0.049021799117326736,\n",
              "  0.0008767120307311416,\n",
              "  -0.0491013377904892,\n",
              "  0.019651763141155243,\n",
              "  -0.11427141726016998,\n",
              "  -0.0041212718933820724,\n",
              "  -0.059363994747400284,\n",
              "  0.08288168162107468,\n",
              "  -0.015205126255750656,\n",
              "  0.05800360441207886,\n",
              "  -0.009099257178604603,\n",
              "  -0.06618720293045044,\n",
              "  -0.04995487257838249,\n",
              "  0.051422737538814545,\n",
              "  -0.030697545036673546,\n",
              "  -0.00599612295627594,\n",
              "  -0.017441147938370705,\n",
              "  -0.0067165326327085495,\n",
              "  -0.026863766834139824,\n",
              "  0.009797872975468636,\n",
              "  0.012698033824563026,\n",
              "  -0.017240023240447044,\n",
              "  -0.040722113102674484,\n",
              "  0.02619202248752117,\n",
              "  -0.036331336945295334,\n",
              "  -0.005993332713842392,\n",
              "  -0.03835161030292511,\n",
              "  -0.0025671017356216908,\n",
              "  0.017816301435232162,\n",
              "  0.015638208016753197,\n",
              "  -0.002425231970846653,\n",
              "  -0.04693610966205597,\n",
              "  0.014938564039766788,\n",
              "  0.057856056839227676,\n",
              "  -0.04266524314880371,\n",
              "  -0.051958806812763214,\n",
              "  0.07029527425765991,\n",
              "  0.0174096692353487,\n",
              "  0.01044029463082552,\n",
              "  0.06522297114133835,\n",
              "  -0.0005443890695460141,\n",
              "  -0.0072739566676318645,\n",
              "  -0.01764906942844391,\n",
              "  -0.01343501266092062,\n",
              "  0.04487789049744606,\n",
              "  -0.04048682376742363,\n",
              "  0.05065847188234329,\n",
              "  -0.006964817643165588,\n",
              "  -0.039026305079460144,\n",
              "  -0.06116586551070213,\n",
              "  0.009619001299142838,\n",
              "  -0.01937313936650753,\n",
              "  -0.07259991019964218,\n",
              "  -0.05417889729142189,\n",
              "  -0.012206215411424637,\n",
              "  0.14574117958545685,\n",
              "  0.07729611545801163,\n",
              "  -0.03489774465560913,\n",
              "  0.02000734768807888,\n",
              "  -0.00971849262714386,\n",
              "  -0.0023303572088479996,\n",
              "  -0.08877687901258469,\n",
              "  0.007430689875036478,\n",
              "  -0.022453872486948967,\n",
              "  2.939167320216669e-33,\n",
              "  -0.03226035088300705,\n",
              "  0.02646695077419281,\n",
              "  -0.06441568583250046,\n",
              "  -0.10495101660490036,\n",
              "  0.007915517315268517,\n",
              "  -0.056241028010845184,\n",
              "  0.0600648857653141,\n",
              "  0.020356711000204086,\n",
              "  0.008408062160015106,\n",
              "  0.00394280394539237,\n",
              "  -0.07579407840967178,\n",
              "  -0.059283699840307236,\n",
              "  -0.07090269774198532,\n",
              "  0.047602903097867966,\n",
              "  0.12866826355457306,\n",
              "  -0.09145348519086838,\n",
              "  -0.06453359127044678,\n",
              "  -0.022725841030478477,\n",
              "  -0.007938683032989502,\n",
              "  0.08817118406295776,\n",
              "  0.030397845432162285,\n",
              "  -0.08102215081453323,\n",
              "  -0.004711293615400791,\n",
              "  0.008305762894451618,\n",
              "  -0.008205698803067207,\n",
              "  0.044841013848781586,\n",
              "  0.003640854964032769,\n",
              "  -0.015380569733679295,\n",
              "  0.06941366195678711,\n",
              "  0.026241688057780266,\n",
              "  0.042122967541217804,\n",
              "  -0.022600207477808,\n",
              "  -0.004685663152486086,\n",
              "  -0.08609002083539963,\n",
              "  -0.0017022470710799098,\n",
              "  -0.036475248634815216,\n",
              "  0.03104810230433941,\n",
              "  -0.07396797835826874,\n",
              "  0.0006451740628108382,\n",
              "  0.057689860463142395,\n",
              "  -0.03433110564947128,\n",
              "  0.10101553797721863,\n",
              "  -0.07978133112192154,\n",
              "  -0.01770963706076145,\n",
              "  0.03582654148340225,\n",
              "  0.07763752341270447,\n",
              "  0.007194378413259983,\n",
              "  0.05085881054401398,\n",
              "  0.03166932985186577,\n",
              "  -0.050254058092832565,\n",
              "  -0.1192030981183052,\n",
              "  -0.002129735192283988,\n",
              "  -0.0107394028455019,\n",
              "  -0.048253513872623444,\n",
              "  0.05193442106246948,\n",
              "  -0.0033458012621849775,\n",
              "  0.045708633959293365,\n",
              "  -0.0063198041170835495,\n",
              "  0.13073934614658356,\n",
              "  0.05694258213043213,\n",
              "  -0.1031755656003952,\n",
              "  -0.021950311958789825,\n",
              "  -0.05125086382031441,\n",
              "  -0.006670759059488773,\n",
              "  -0.04244102165102959,\n",
              "  0.07283089309930801,\n",
              "  0.08295755833387375,\n",
              "  -0.01451050490140915,\n",
              "  -0.050436634570360184,\n",
              "  -0.0063996752724051476,\n",
              "  -0.05111794173717499,\n",
              "  -0.06090034544467926,\n",
              "  0.12017730623483658,\n",
              "  -0.007007972337305546,\n",
              "  -0.018361017107963562,\n",
              "  0.05737388879060745,\n",
              "  -0.06952648609876633,\n",
              "  -0.0329073891043663,\n",
              "  -0.046019524335861206,\n",
              "  -0.04026426374912262,\n",
              "  -0.03974202275276184,\n",
              "  0.04068472236394882,\n",
              "  0.06414211541414261,\n",
              "  0.08900655806064606,\n",
              "  -0.00060390739236027,\n",
              "  0.06864351779222488,\n",
              "  -0.04542217403650284,\n",
              "  -0.012834936380386353,\n",
              "  0.014704265631735325,\n",
              "  0.08229125291109085,\n",
              "  -0.011864698491990566,\n",
              "  -0.007569513283669949,\n",
              "  0.029478946700692177,\n",
              "  -0.017556926235556602,\n",
              "  0.03026776760816574,\n",
              "  -3.4444798318695305e-33,\n",
              "  0.013093586079776287,\n",
              "  -0.05642778053879738,\n",
              "  -0.05393407866358757,\n",
              "  0.02010548673570156,\n",
              "  0.002186316065490246,\n",
              "  0.021474365144968033,\n",
              "  -0.01675189472734928,\n",
              "  0.11519582569599152,\n",
              "  0.009137553162872791,\n",
              "  0.002790238708257675,\n",
              "  -0.028134936466813087,\n",
              "  0.08885099738836288,\n",
              "  0.07289770990610123,\n",
              "  0.02972547896206379,\n",
              "  0.03313830494880676,\n",
              "  -0.03830660134553909,\n",
              "  -0.015428598038852215,\n",
              "  -0.025887154042720795,\n",
              "  0.02991276979446411,\n",
              "  0.021465003490447998,\n",
              "  0.055984679609537125,\n",
              "  0.02411733567714691,\n",
              "  0.013602275401353836,\n",
              "  0.001853855443187058,\n",
              "  0.046712420880794525,\n",
              "  0.019653165712952614,\n",
              "  -0.0611024871468544,\n",
              "  0.006502089090645313,\n",
              "  0.0441303625702858,\n",
              "  -0.030408691614866257,\n",
              "  0.003392198821529746,\n",
              "  -0.07827484607696533,\n",
              "  0.08200996369123459,\n",
              "  0.021945785731077194,\n",
              "  -0.04214276745915413,\n",
              "  -0.011046931147575378,\n",
              "  0.11221751570701599,\n",
              "  -0.03547649085521698,\n",
              "  -0.02034923806786537,\n",
              "  0.05863974243402481,\n",
              "  0.061948224902153015,\n",
              "  0.004163042642176151,\n",
              "  0.025604233145713806,\n",
              "  0.07054829597473145,\n",
              "  0.026611244305968285,\n",
              "  0.03901861235499382,\n",
              "  -0.0028351128567010164,\n",
              "  -0.013862921856343746,\n",
              "  -0.03907373547554016,\n",
              "  -0.10136910527944565,\n",
              "  0.015273002907633781,\n",
              "  -0.0636049285531044,\n",
              "  0.009429153054952621,\n",
              "  -0.03778139874339104,\n",
              "  -0.07231791317462921,\n",
              "  -0.05598380044102669,\n",
              "  0.0146296676248312,\n",
              "  0.006302482448518276,\n",
              "  0.036601871252059937,\n",
              "  -0.07091113924980164,\n",
              "  0.03455745428800583,\n",
              "  0.021303288638591766,\n",
              "  0.018934456631541252,\n",
              "  0.01931314915418625,\n",
              "  0.007075129076838493,\n",
              "  0.018622223287820816,\n",
              "  0.05089221149682999,\n",
              "  0.03337225690484047,\n",
              "  -0.008652801625430584,\n",
              "  -0.023814190179109573,\n",
              "  -0.05765106528997421,\n",
              "  -0.10482978075742722,\n",
              "  0.013372018001973629,\n",
              "  -0.01933068409562111,\n",
              "  -0.016363972797989845,\n",
              "  0.04313588887453079,\n",
              "  -0.019315389916300774,\n",
              "  0.042876679450273514,\n",
              "  0.07228625565767288,\n",
              "  -0.004229306243360043,\n",
              "  0.025138597935438156,\n",
              "  0.07576548308134079,\n",
              "  0.033386338502168655,\n",
              "  0.022974086925387383,\n",
              "  0.07685324549674988,\n",
              "  -0.05225932598114014,\n",
              "  0.043289393186569214,\n",
              "  -0.012385099194943905,\n",
              "  -0.036590274423360825,\n",
              "  -0.012774484232068062,\n",
              "  -0.046136267483234406,\n",
              "  0.051983099430799484,\n",
              "  -0.06112852692604065,\n",
              "  -0.0003355621884111315,\n",
              "  -0.006177410017699003,\n",
              "  -2.835624535180159e-08,\n",
              "  0.06613793969154358,\n",
              "  0.011798004619777203,\n",
              "  0.037113726139068604,\n",
              "  0.04696718230843544,\n",
              "  0.043035347014665604,\n",
              "  -0.09251100569963455,\n",
              "  0.046135202050209045,\n",
              "  0.08055239915847778,\n",
              "  0.10685128718614578,\n",
              "  -0.007414942141622305,\n",
              "  -0.0413203239440918,\n",
              "  -0.08303714543581009,\n",
              "  -0.018203390762209892,\n",
              "  0.013738766312599182,\n",
              "  0.043958164751529694,\n",
              "  0.037307366728782654,\n",
              "  0.03315778449177742,\n",
              "  0.0881715714931488,\n",
              "  0.0019880577456206083,\n",
              "  -0.07271483540534973,\n",
              "  0.0230609979480505,\n",
              "  0.04958247020840645,\n",
              "  0.09864996373653412,\n",
              "  -0.09664388746023178,\n",
              "  -0.0389941930770874,\n",
              "  0.040474724024534225,\n",
              "  -0.053038567304611206,\n",
              "  0.030482791364192963,\n",
              "  0.06002917140722275,\n",
              "  0.01091479416936636,\n",
              "  -0.10208377242088318,\n",
              "  0.03962486982345581,\n",
              "  0.03992467746138573,\n",
              "  -0.08412328362464905,\n",
              "  0.09101279079914093,\n",
              "  -0.06123001500964165,\n",
              "  -0.03717247396707535,\n",
              "  -0.019029760733246803,\n",
              "  0.0963117778301239,\n",
              "  -0.02458466775715351,\n",
              "  -0.010751205496490002,\n",
              "  0.0013019784819334745,\n",
              "  -0.07538682967424393,\n",
              "  -0.018940189853310585,\n",
              "  0.054801248013973236,\n",
              "  0.003068663412705064,\n",
              "  -0.1022912859916687,\n",
              "  -0.1027493104338646,\n",
              "  0.0010229793842881918,\n",
              "  0.03838779032230377,\n",
              "  -0.03387368097901344,\n",
              "  -0.006812311243265867,\n",
              "  -0.028700852766633034,\n",
              "  0.06181854382157326,\n",
              "  0.012259316630661488,\n",
              "  0.02560870721936226,\n",
              "  -0.03962231054902077,\n",
              "  -0.06302027404308319,\n",
              "  -0.10198362916707993,\n",
              "  0.09703315049409866,\n",
              "  0.12165297567844391,\n",
              "  -0.104803167283535,\n",
              "  -0.04797930270433426,\n",
              "  0.07281223684549332]]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_vectors = getado[\"embeddings\"]\n",
        "word_list = getado[\"documents\"]\n",
        "word_vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db77eb0a",
      "metadata": {
        "papermill": {
          "duration": 0.017628,
          "end_time": "2024-07-12T16:09:49.762315",
          "exception": false,
          "start_time": "2024-07-12T16:09:49.744687",
          "status": "completed"
        },
        "tags": [],
        "id": "db77eb0a"
      },
      "source": [
        "Once we have our information inside the Database we can query It, and ask for data that matches our needs. The search is done inside the content of the document, and it dosn't look for the exact word, or phrase. The results will be based on the similarity between the search terms and the content of documents.\n",
        "\n",
        "The metadata is not used in the search, but they can be utilized for filtering or refining the results after the initial search.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "791c4f05",
      "metadata": {
        "papermill": {
          "duration": 0.017587,
          "end_time": "2024-07-12T16:09:49.798378",
          "exception": false,
          "start_time": "2024-07-12T16:09:49.780791",
          "status": "completed"
        },
        "tags": [],
        "id": "791c4f05"
      },
      "source": [
        "# Loading the model and creating the prompt\n",
        "TRANSFORMERS!!\n",
        "Time to use the library **transformers**, the most famous library from [hugging face](https://huggingface.co/) for working with language models.\n",
        "\n",
        "We are importing:\n",
        "* **Autotokenizer**: It is a utility class for tokenizing text inputs that are compatible with various pre-trained language models.\n",
        "* **AutoModelForCasualLLM**: it provides an interface to pre-trained language models specifically designed for language generation tasks using causal language modeling (e.g., GPT models), or the model used in this notebook ***databricks/dolly-v2-3b***.\n",
        "* **pipeline**: provides a simple interface for performing various natural language processing (NLP) tasks, such as text generation (our case) or text classification.\n",
        "\n",
        "The model I have selected is [TinyLlama-1.1B-Chat-v1.0](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0), which is one of the smartest Small Language Models. Even so, it still has 1.1 billion parameters.\n",
        "\n",
        "Please, feel free to test [different Models](https://huggingface.co/models?pipeline_tag=text-generation&sort=trending), you need to search for NLP models trained for text-generation. My recomendation is choose \"small\" models, or we will run out of memory in kaggle.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "302fa173",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-12T16:09:49.836569Z",
          "iopub.status.busy": "2024-07-12T16:09:49.835514Z",
          "iopub.status.idle": "2024-07-12T16:10:42.741119Z",
          "shell.execute_reply": "2024-07-12T16:10:42.73997Z"
        },
        "papermill": {
          "duration": 52.928172,
          "end_time": "2024-07-12T16:10:42.744425",
          "exception": false,
          "start_time": "2024-07-12T16:09:49.816253",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "fcc468074dbb4b6d8fb5115607381b4a",
            "5e38eaa07c044cba828b6d4894c4d6f5",
            "c3c91232aac042028901b94b67ce1d53",
            "1bcfbf7ff1814ef595c79150cd8885e7",
            "f5a3bc0d217f498b9923695621035b26",
            "611767e0477c4cbb9aad137eaaa02f36",
            "a44e190786be4de480713968b18d500d"
          ]
        },
        "id": "302fa173",
        "outputId": "6a83dc1e-8f15-4ca7-910a-b9f881fdd3a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
            "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
            "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
            "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
            "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
            "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcc468074dbb4b6d8fb5115607381b4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e38eaa07c044cba828b6d4894c4d6f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3c91232aac042028901b94b67ce1d53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bcfbf7ff1814ef595c79150cd8885e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5a3bc0d217f498b9923695621035b26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "611767e0477c4cbb9aad137eaaa02f36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a44e190786be4de480713968b18d500d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "#model_id = \"databricks/dolly-v2-3b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "lm_model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81f49de4",
      "metadata": {
        "papermill": {
          "duration": 0.01964,
          "end_time": "2024-07-12T16:10:42.784018",
          "exception": false,
          "start_time": "2024-07-12T16:10:42.764378",
          "status": "completed"
        },
        "tags": [],
        "id": "81f49de4"
      },
      "source": [
        "The next step is to initialize the pipeline using the objects created above.\n",
        "\n",
        "The model's response is limited to 256 tokens, for this project I'm not interested in a longer response, but it can easily be extended to whatever length you want.\n",
        "\n",
        "Setting ***device_map*** to ***auto*** we are instructing the model to automaticaly select the most appropiate device: CPU or GPU for processing the text generation.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "557e9cce",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-12T16:10:42.826013Z",
          "iopub.status.busy": "2024-07-12T16:10:42.825179Z",
          "iopub.status.idle": "2024-07-12T16:10:42.831258Z",
          "shell.execute_reply": "2024-07-12T16:10:42.830194Z"
        },
        "papermill": {
          "duration": 0.029775,
          "end_time": "2024-07-12T16:10:42.833699",
          "exception": false,
          "start_time": "2024-07-12T16:10:42.803924",
          "status": "completed"
        },
        "tags": [],
        "id": "557e9cce"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=lm_model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=256,\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f83b350",
      "metadata": {
        "papermill": {
          "duration": 0.019134,
          "end_time": "2024-07-12T16:10:42.872329",
          "exception": false,
          "start_time": "2024-07-12T16:10:42.853195",
          "status": "completed"
        },
        "tags": [],
        "id": "6f83b350"
      },
      "source": [
        "## Creating the extended prompt\n",
        "To create the prompt we use the result from query the Vector Database  and the sentence introduced by the user.\n",
        "\n",
        "The prompt have two parts, the **relevant context** that is the information recovered from the database and the **user's question**.\n",
        "\n",
        "We only need to join the two parts together to create the prompt that we are going to send to the model.\n",
        "\n",
        "You can limit the lenght of the context passed to the model, because we can get some Memory problems with one of the datasets that contains a realy large text in the document part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50cf6013",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-12T16:10:42.912851Z",
          "iopub.status.busy": "2024-07-12T16:10:42.91246Z",
          "iopub.status.idle": "2024-07-12T16:10:42.921178Z",
          "shell.execute_reply": "2024-07-12T16:10:42.920081Z"
        },
        "papermill": {
          "duration": 0.031766,
          "end_time": "2024-07-12T16:10:42.923488",
          "exception": false,
          "start_time": "2024-07-12T16:10:42.891722",
          "status": "completed"
        },
        "tags": [],
        "id": "50cf6013",
        "outputId": "9d28b511-409f-4aee-9fe5-b3836336d6a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nRelevant context: #The Legendary Toshiba is Officially Done With Making Laptops #3 gaming laptop deals you can’t afford to miss today #Lenovo and HP control half of the global laptop market #Asus ROG Zephyrus G14 gaming laptop announced in India #Acer Swift 3 featuring a 10th-generation Intel Ice Lake CPU, 2K screen, and more launched in India for INR 64999 (US$865) #Apple's Next MacBook Could Be the Cheapest in Company's History #Features of Huawei's Desktop Computer Revealed #Redmi to launch its first gaming laptop on August 14: Here are all the details #Toshiba shuts the lid on laptops after 35 years #This is the cheapest Windows PC by a mile and it even has a spare SSD slot\\nConsidering the relevant context, answer the question.\\nQuestion: Can I buy a new Toshiba laptop?\\nAnswer: \""
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"Can I buy a new Toshiba laptop?\"\n",
        "context = \" \".join([f\"#{str(i)}\" for i in results[\"documents\"][0]])\n",
        "#context = context[0:5120]\n",
        "prompt_template = f\"\"\"\n",
        "Relevant context: {context}\n",
        "Considering the relevant context, answer the question.\n",
        "Question: {question}\n",
        "Answer: \"\"\"\n",
        "prompt_template"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b75750aa",
      "metadata": {
        "papermill": {
          "duration": 0.019319,
          "end_time": "2024-07-12T16:10:42.962467",
          "exception": false,
          "start_time": "2024-07-12T16:10:42.943148",
          "status": "completed"
        },
        "tags": [],
        "id": "b75750aa"
      },
      "source": [
        "Now all that remains is to send the prompt to the model and wait for its response!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a9a2511",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-12T16:10:43.004278Z",
          "iopub.status.busy": "2024-07-12T16:10:43.003859Z",
          "iopub.status.idle": "2024-07-12T16:10:55.374325Z",
          "shell.execute_reply": "2024-07-12T16:10:55.373189Z"
        },
        "papermill": {
          "duration": 12.394809,
          "end_time": "2024-07-12T16:10:55.377008",
          "exception": false,
          "start_time": "2024-07-12T16:10:42.982199",
          "status": "completed"
        },
        "tags": [],
        "id": "8a9a2511",
        "outputId": "267a78ed-3ad7-43a1-fe99-2e34ff6d554c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Relevant context: #The Legendary Toshiba is Officially Done With Making Laptops #3 gaming laptop deals you can’t afford to miss today #Lenovo and HP control half of the global laptop market #Asus ROG Zephyrus G14 gaming laptop announced in India #Acer Swift 3 featuring a 10th-generation Intel Ice Lake CPU, 2K screen, and more launched in India for INR 64999 (US$865) #Apple's Next MacBook Could Be the Cheapest in Company's History #Features of Huawei's Desktop Computer Revealed #Redmi to launch its first gaming laptop on August 14: Here are all the details #Toshiba shuts the lid on laptops after 35 years #This is the cheapest Windows PC by a mile and it even has a spare SSD slot\n",
            "Considering the relevant context, answer the question.\n",
            "Question: Can I buy a new Toshiba laptop?\n",
            "Answer: \n",
            "Based on the given material, the answer to the question is no. Toshiba has discontinued making laptops.\n"
          ]
        }
      ],
      "source": [
        "lm_response = pipe(prompt_template)\n",
        "print(lm_response[0][\"generated_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "655bea52",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-12T22:01:56.993351Z",
          "iopub.status.busy": "2023-07-12T22:01:56.992775Z",
          "iopub.status.idle": "2023-07-12T22:01:57.001309Z",
          "shell.execute_reply": "2023-07-12T22:01:56.999431Z",
          "shell.execute_reply.started": "2023-07-12T22:01:56.993305Z"
        },
        "papermill": {
          "duration": 0.020258,
          "end_time": "2024-07-12T16:10:55.418075",
          "exception": false,
          "start_time": "2024-07-12T16:10:55.397817",
          "status": "completed"
        },
        "tags": [],
        "id": "655bea52"
      },
      "source": [
        "# Conclusions, Fork and Improve\n",
        "A very short notebook, but with a lot of content.\n",
        "\n",
        "We have used a vector database to store information. Then move on to retrieve it and use it to create an extended prompt that we've used to call one of the newer large language models available in Hugging Face.\n",
        "\n",
        "The model has returned a response to us taking into account the context that we have passed to it in the prompt.\n",
        "\n",
        "This way of working with language models is very powerful.\n",
        "\n",
        "We can make the model use our information without the need for Fine Tuning. This technique really has some very big advantages over fine tuning.\n",
        "\n",
        "Please don't stop here.\n",
        "\n",
        "* The notebook is prepared to use two more Datasets. Do tests with it.\n",
        "\n",
        "* Find another model on Hugging Face and compare it.\n",
        "\n",
        "* Modify the way to create the prompt.\n",
        "\n",
        "## Continue learning\n",
        "This notebook is part of a [course on large language models](https://github.com/peremartra/Large-Language-Model-Notebooks-Course) I'm working on and it's available on [GitHub](https://github.com/peremartra/Large-Language-Model-Notebooks-Course). You can see the other lessons and if you like it, don't forget to subscribe to receive notifications of new lessons.\n",
        "\n",
        "Other notebooks in the Large Language Models series:\n",
        "https://www.kaggle.com/code/peremartramanonellas/ask-your-documents-with-langchain-vectordb-hf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9927b108",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-12T22:17:34.636604Z",
          "iopub.status.busy": "2023-07-12T22:17:34.63605Z",
          "iopub.status.idle": "2023-07-12T22:17:34.644497Z",
          "shell.execute_reply": "2023-07-12T22:17:34.642819Z",
          "shell.execute_reply.started": "2023-07-12T22:17:34.636566Z"
        },
        "papermill": {
          "duration": 0.019543,
          "end_time": "2024-07-12T16:10:55.45779",
          "exception": false,
          "start_time": "2024-07-12T16:10:55.438247",
          "status": "completed"
        },
        "tags": [],
        "id": "9927b108"
      },
      "source": [
        "### If you liked the notebook Please consider ***UPVOTING IT***. It helps others to discover it, and encourages me to continue publishing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b971c6f",
      "metadata": {
        "papermill": {
          "duration": 0.019574,
          "end_time": "2024-07-12T16:10:55.497085",
          "exception": false,
          "start_time": "2024-07-12T16:10:55.477511",
          "status": "completed"
        },
        "tags": [],
        "id": "1b971c6f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 9096686,
          "datasetId": 1977878,
          "sourceId": 8934230,
          "sourceType": "datasetVersion"
        },
        {
          "databundleVersionId": 6183126,
          "datasetId": 3496946,
          "sourceId": 6104553,
          "sourceType": "datasetVersion"
        },
        {
          "databundleVersionId": 1461511,
          "datasetId": 836401,
          "sourceId": 1428159,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30527,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 264.244307,
      "end_time": "2024-07-12T16:10:58.241005",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-07-12T16:06:33.996698",
      "version": "2.4.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}